{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9618e505-7b98-4eb0-8eaf-f2180041b26b",
   "metadata": {},
   "source": [
    "### Explore the possible outputs of DINO, the interface designed by meta, and extending it for LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e16c0c-7856-4c64-a23b-6220c71f93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.hub.set_dir(\"../pretrained_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37a5a17-9482-4134-a571-fd26258a1a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in ../pretrained_weights/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "# load the backbone model\n",
    "device = 'cpu' #0 if torch.cuda.is_available() else \"cpu\"\n",
    "dino_backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vits8').to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d93bcd-4d5a-469a-b510-a375a9f7c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(dino_backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ed575-23e4-40db-9dca-eae9261054fe",
   "metadata": {},
   "source": [
    "### Look at the user interface of DINO (returning class token, intermed. outputs, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0f8099-7ecd-4c5d-9eb7-7bd4c04058d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tensor = torch.randn(8, 3, 224, 224).to(device) # BxCxHxW\n",
    "out = dino_backbone.forward(in_tensor)\n",
    "out_intermediate = dino_backbone.get_intermediate_layers(in_tensor, n=3) # eg. the last 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3d94c5-7340-4715-86f7-e614d14b91d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 384])\n",
      "3\n",
      "torch.Size([8, 785, 384])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out.shape) # class token\n",
    "print(len(out_intermediate))\n",
    "print(out_intermediate[0].shape)\n",
    "out_intermediate[-1][:, 0] == out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a8d78-21e6-4321-adf3-1ac0ba7d0a88",
   "metadata": {},
   "source": [
    "### Look at sub-components of dino_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83d58f9e-7ad5-4bad-b55b-67b169d1fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block(\n",
      "  (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# go deeper into the structure\n",
    "print(dino_backbone.blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ece5bdf-c867-4476-bba1-7475c52894d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=384, out_features=1152, bias=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# isolate the linear weights in qkv\n",
    "print(dino_backbone.blocks[0].attn.qkv)\n",
    "print(dino_backbone.blocks[0].attn.qkv.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2bacfe-84cb-48f6-a936-aa06879055f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we replace the qkv in Attention.qkv with a custom module\n",
    "class Lora_qkv(nn.Module):\n",
    "    def __init__(self, qkv, qa, qb, va, vb):\n",
    "        super().__init__()\n",
    "        self.qkv = qkv\n",
    "        self.qa = qa\n",
    "        self.qb = qb\n",
    "        self.va = va\n",
    "        self.vb = vb\n",
    "        self.dim = self.qkv.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        old_qkv = self.qkv(x) # B, N, 3C\n",
    "        new_q = self.qb(self.qa(x)) # B, N, C\n",
    "        new_v = self.vb(self.va(x)) # B, N, C\n",
    "        \n",
    "        old_qkv[:, :, : self.dim] += new_q # first C channels belong to q\n",
    "        old_qkv[:, :, -self.dim:] += new_v # last C channels belong to v\n",
    "        return old_qkv\n",
    "\n",
    "# implementing the qv lora mechanism\n",
    "# design similar to https://github.com/BeileiCui/SurgicalDINO/blob/main/surgicaldino.py\n",
    "class Lora_vit(nn.Module):\n",
    "    def __init__(self, base_vit, lora_rank=4, full_ft=False):\n",
    "        super().__init__()\n",
    "        if not full_ft:\n",
    "            # constrain the model to only train lora weights\n",
    "            for param in base_vit.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.base = base_vit\n",
    "        \n",
    "        self.r = lora_rank\n",
    "        self.in_ftrs = self.base.blocks[0].attn.qkv.in_features\n",
    "        out_ftrs_qkv = self.base.blocks[0].attn.qkv.out_features\n",
    "        assert out_ftrs_qkv % 3 == 0\n",
    "        self.out_ftrs = out_ftrs_qkv // 3\n",
    "        \n",
    "        self.initialize_lora_layers()\n",
    "\n",
    "    def initialize_lora_layers(self):\n",
    "        # instantiate lora weights for each of the blocks\n",
    "        qa, qb = [], []\n",
    "        va, vb = [], []\n",
    "        for i, block in enumerate(self.base.blocks):\n",
    "            qa.append(nn.Linear(self.in_ftrs, self.r, bias=False))\n",
    "            qb.append(nn.Linear(self.r, self.out_ftrs, bias=False))\n",
    "            va.append(nn.Linear(self.in_ftrs, self.r, bias=False))\n",
    "            vb.append(nn.Linear(self.r, self.out_ftrs, bias=False))\n",
    "            block.attn.qkv = Lora_qkv(block.attn.qkv, qa[i], qb[i], va[i], vb[i]) \n",
    "\n",
    "    def forward(self, x): # class token\n",
    "        return self.base.forward(x)\n",
    "\n",
    "    def get_intermediate_layers(self, x, n=1):\n",
    "        return self.base.get_intermediate_layers(x, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9c11b8-61bd-42fd-b7ac-6eede8634ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in ../pretrained_weights/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "dino_backbone_2 = torch.hub.load('facebookresearch/dino:main', 'dino_vits8').to(device).eval()\n",
    "lora_test = Lora_vit(dino_backbone_2, lora_rank=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03765bf0-2a7d-4b35-a74c-4d4211a4d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lora_vit(\n",
      "  (base): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Lora_qkv(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (qa): Linear(in_features=384, out_features=4, bias=False)\n",
      "            (qb): Linear(in_features=4, out_features=384, bias=False)\n",
      "            (va): Linear(in_features=384, out_features=4, bias=False)\n",
      "            (vb): Linear(in_features=4, out_features=384, bias=False)\n",
      "          )\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lora_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456becae-3d01-447b-b904-d9ed9527a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lora_qkv(\n",
      "  (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "  (qa): Linear(in_features=384, out_features=4, bias=False)\n",
      "  (qb): Linear(in_features=4, out_features=384, bias=False)\n",
      "  (va): Linear(in_features=384, out_features=4, bias=False)\n",
      "  (vb): Linear(in_features=4, out_features=384, bias=False)\n",
      ")\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# isolate the linear weights in qkv\n",
    "print(lora_test.base.blocks[0].attn.qkv)\n",
    "print(lora_test.base.blocks[0].attn.qkv.qkv.weight.requires_grad)\n",
    "print(lora_test.base.blocks[0].attn.qkv.qa.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "010d7098-d4bd-43ec-a012-1ea9c7e8967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_lora = lora_test.forward(in_tensor)\n",
    "out_lora_intermediate = lora_test.get_intermediate_layers(in_tensor, n=3) # eg. the last 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dffb670-87bd-459e-bd48-65f46a1ad75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 384])\n",
      "3\n",
      "torch.Size([8, 785, 384])\n",
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out_lora.shape) # class token\n",
    "print(len(out_lora_intermediate))\n",
    "print(out_lora_intermediate[0].shape)\n",
    "print(out_lora_intermediate[-1][:, 0] == out_lora)\n",
    "out_lora == out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c241578e-7a83-4de7-82f0-4e6502765d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "base.cls_token \t torch.Size([1, 1, 384])\n",
      "base.pos_embed \t torch.Size([1, 785, 384])\n",
      "base.patch_embed.proj.weight \t torch.Size([384, 3, 8, 8])\n",
      "base.patch_embed.proj.bias \t torch.Size([384])\n",
      "base.blocks.0.norm1.weight \t torch.Size([384])\n",
      "base.blocks.0.norm1.bias \t torch.Size([384])\n",
      "base.blocks.0.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.0.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.0.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.0.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.0.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.0.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.0.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.0.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.0.norm2.weight \t torch.Size([384])\n",
      "base.blocks.0.norm2.bias \t torch.Size([384])\n",
      "base.blocks.0.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.0.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.0.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.0.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.1.norm1.weight \t torch.Size([384])\n",
      "base.blocks.1.norm1.bias \t torch.Size([384])\n",
      "base.blocks.1.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.1.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.1.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.1.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.1.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.1.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.1.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.1.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.1.norm2.weight \t torch.Size([384])\n",
      "base.blocks.1.norm2.bias \t torch.Size([384])\n",
      "base.blocks.1.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.1.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.1.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.1.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.2.norm1.weight \t torch.Size([384])\n",
      "base.blocks.2.norm1.bias \t torch.Size([384])\n",
      "base.blocks.2.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.2.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.2.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.2.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.2.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.2.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.2.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.2.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.2.norm2.weight \t torch.Size([384])\n",
      "base.blocks.2.norm2.bias \t torch.Size([384])\n",
      "base.blocks.2.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.2.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.2.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.2.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.3.norm1.weight \t torch.Size([384])\n",
      "base.blocks.3.norm1.bias \t torch.Size([384])\n",
      "base.blocks.3.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.3.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.3.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.3.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.3.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.3.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.3.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.3.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.3.norm2.weight \t torch.Size([384])\n",
      "base.blocks.3.norm2.bias \t torch.Size([384])\n",
      "base.blocks.3.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.3.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.3.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.3.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.4.norm1.weight \t torch.Size([384])\n",
      "base.blocks.4.norm1.bias \t torch.Size([384])\n",
      "base.blocks.4.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.4.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.4.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.4.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.4.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.4.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.4.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.4.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.4.norm2.weight \t torch.Size([384])\n",
      "base.blocks.4.norm2.bias \t torch.Size([384])\n",
      "base.blocks.4.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.4.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.4.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.4.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.5.norm1.weight \t torch.Size([384])\n",
      "base.blocks.5.norm1.bias \t torch.Size([384])\n",
      "base.blocks.5.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.5.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.5.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.5.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.5.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.5.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.5.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.5.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.5.norm2.weight \t torch.Size([384])\n",
      "base.blocks.5.norm2.bias \t torch.Size([384])\n",
      "base.blocks.5.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.5.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.5.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.5.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.6.norm1.weight \t torch.Size([384])\n",
      "base.blocks.6.norm1.bias \t torch.Size([384])\n",
      "base.blocks.6.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.6.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.6.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.6.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.6.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.6.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.6.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.6.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.6.norm2.weight \t torch.Size([384])\n",
      "base.blocks.6.norm2.bias \t torch.Size([384])\n",
      "base.blocks.6.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.6.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.6.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.6.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.7.norm1.weight \t torch.Size([384])\n",
      "base.blocks.7.norm1.bias \t torch.Size([384])\n",
      "base.blocks.7.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.7.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.7.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.7.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.7.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.7.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.7.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.7.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.7.norm2.weight \t torch.Size([384])\n",
      "base.blocks.7.norm2.bias \t torch.Size([384])\n",
      "base.blocks.7.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.7.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.7.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.7.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.8.norm1.weight \t torch.Size([384])\n",
      "base.blocks.8.norm1.bias \t torch.Size([384])\n",
      "base.blocks.8.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.8.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.8.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.8.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.8.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.8.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.8.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.8.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.8.norm2.weight \t torch.Size([384])\n",
      "base.blocks.8.norm2.bias \t torch.Size([384])\n",
      "base.blocks.8.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.8.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.8.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.8.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.9.norm1.weight \t torch.Size([384])\n",
      "base.blocks.9.norm1.bias \t torch.Size([384])\n",
      "base.blocks.9.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.9.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.9.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.9.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.9.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.9.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.9.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.9.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.9.norm2.weight \t torch.Size([384])\n",
      "base.blocks.9.norm2.bias \t torch.Size([384])\n",
      "base.blocks.9.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.9.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.9.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.9.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.10.norm1.weight \t torch.Size([384])\n",
      "base.blocks.10.norm1.bias \t torch.Size([384])\n",
      "base.blocks.10.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.10.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.10.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.10.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.10.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.10.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.10.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.10.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.10.norm2.weight \t torch.Size([384])\n",
      "base.blocks.10.norm2.bias \t torch.Size([384])\n",
      "base.blocks.10.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.10.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.10.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.10.mlp.fc2.bias \t torch.Size([384])\n",
      "base.blocks.11.norm1.weight \t torch.Size([384])\n",
      "base.blocks.11.norm1.bias \t torch.Size([384])\n",
      "base.blocks.11.attn.qkv.qkv.weight \t torch.Size([1152, 384])\n",
      "base.blocks.11.attn.qkv.qkv.bias \t torch.Size([1152])\n",
      "base.blocks.11.attn.qkv.qa.weight \t torch.Size([4, 384])\n",
      "base.blocks.11.attn.qkv.qb.weight \t torch.Size([384, 4])\n",
      "base.blocks.11.attn.qkv.va.weight \t torch.Size([4, 384])\n",
      "base.blocks.11.attn.qkv.vb.weight \t torch.Size([384, 4])\n",
      "base.blocks.11.attn.proj.weight \t torch.Size([384, 384])\n",
      "base.blocks.11.attn.proj.bias \t torch.Size([384])\n",
      "base.blocks.11.norm2.weight \t torch.Size([384])\n",
      "base.blocks.11.norm2.bias \t torch.Size([384])\n",
      "base.blocks.11.mlp.fc1.weight \t torch.Size([1536, 384])\n",
      "base.blocks.11.mlp.fc1.bias \t torch.Size([1536])\n",
      "base.blocks.11.mlp.fc2.weight \t torch.Size([384, 1536])\n",
      "base.blocks.11.mlp.fc2.bias \t torch.Size([384])\n",
      "base.norm.weight \t torch.Size([384])\n",
      "base.norm.bias \t torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "lora_test.train()\n",
    "for param_tensor in lora_test.state_dict():\n",
    "    print(param_tensor, \"\\t\", lora_test.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc228661-1ebb-4010-af1f-b85cb3a1ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in ../pretrained_weights/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# try saving and loading state_dict\n",
    "path = '../lora_test.pt'\n",
    "torch.save(lora_test.state_dict(), path)\n",
    "\n",
    "dino_backbone_3 = torch.hub.load('facebookresearch/dino:main', 'dino_vits8').to(device).eval()\n",
    "lora_test_new = Lora_vit(dino_backbone_3, lora_rank=4)\n",
    "\n",
    "out_lora_2 = lora_test_new.forward(in_tensor)\n",
    "print(out_lora_2 == out_lora) # should be false\n",
    "\n",
    "lora_test_new.load_state_dict(torch.load(path))\n",
    "out_lora_3 = lora_test_new.forward(in_tensor)\n",
    "print(out_lora_3 == out_lora) # should be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a5de6cf-5676-46d9-bd3e-45b653518d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lora_qkv(\n",
      "  (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "  (qa): Linear(in_features=384, out_features=4, bias=False)\n",
      "  (qb): Linear(in_features=4, out_features=384, bias=False)\n",
      "  (va): Linear(in_features=384, out_features=4, bias=False)\n",
      "  (vb): Linear(in_features=4, out_features=384, bias=False)\n",
      ")\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check that the weight gradient behavior is consistent with before load\n",
    "print(lora_test_new.base.blocks[0].attn.qkv)\n",
    "print(lora_test_new.base.blocks[0].attn.qkv.qkv.weight.requires_grad) # should be equal to full_ft\n",
    "print(lora_test_new.base.blocks[0].attn.qkv.qa.weight.requires_grad) # should be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4770199-b081-45a8-ad7d-3773599bf472",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_path = '../logs/training_1/checkpoint0009.pth'\n",
    "\n",
    "def load_lora_vit_from_dino_ckpt(model, ckpt_path):\n",
    "    # we are loading the teacher model from the DINO checkpoint\n",
    "    teacher = torch.load(ckpt_path)['teacher']\n",
    "    \n",
    "    # edit the dictionary to remove the projector and rename backbone entries\n",
    "    for k in list(teacher.keys()):\n",
    "        if 'backbone' in k:\n",
    "            teacher[k.replace('backbone.', '')] = teacher.pop(k)\n",
    "        else:\n",
    "            teacher.pop(k)\n",
    "\n",
    "    # model is the lora_vit model with a consistent lora rank as the checkpoint\n",
    "    model.load_state_dict(teacher, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bdc46a1-d8e3-4b66-9bf5-41f0a0ceab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3 = lora_test_new.forward(in_tensor)\n",
    "load_lora_vit_from_dino_ckpt(lora_test_new, trained_path)\n",
    "out4 = lora_test_new.forward(in_tensor)\n",
    "out4 == out3 # should be false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667909e2-4f40-4959-9be9-1a24a7a2af86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
