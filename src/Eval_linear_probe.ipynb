{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8126b6-c574-4f22-aab9-fdccfa3e612b",
   "metadata": {},
   "source": [
    "## Exploring linear probing classification using the DINO class token as the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41cbfc0d-96d8-4666-94e0-a0a53ff80a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from model_lora_vit import get_vit, load_lora_vit_from_dino_ckpt\n",
    "from data_transforms import get_random_transform, get_deterministic_transform\n",
    "from dataloader_tmed import TMED2\n",
    "\n",
    "torch.hub.set_dir(\"../pretrained_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397fe984-ca76-4fab-856a-3f1ac42eaecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the GPU\n",
    "device = 3 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# configure batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# configure linear probe training\n",
    "embedding_dim = 384 # change this for other architectures\n",
    "hidden_dim = 256 # >0 for optimizing a second linear layer\n",
    "num_classes_AS = 3\n",
    "lr = 0.0001\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e83420-5025-469c-9a3f-94060df83607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in ../pretrained_weights/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized without LoRA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lora_vit(\n",
       "  (base): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the backbone model, ensure params are consistent with ckpt\n",
    "experiment = 'imagenet'\n",
    "if experiment == 'imagenet':\n",
    "    ckpt_path = None\n",
    "    lora_rank = 0\n",
    "elif experiment == 'full':\n",
    "    ckpt_path = '../logs/training_base/checkpoint.pth'\n",
    "    lora_rank = 0\n",
    "elif experiment == 'lora4':\n",
    "    ckpt_path = '../logs/training_1/checkpoint0009.pth'\n",
    "    lora_rank = 4\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "arch = 'vit_small'\n",
    "patch_size = 8\n",
    "if ckpt_path == None:\n",
    "    # load the default DINO model\n",
    "    model = get_vit(arch, patch_size, lora_rank=0)\n",
    "else:\n",
    "    model = get_vit(arch, patch_size, lora_rank)\n",
    "    load_lora_vit_from_dino_ckpt(model, ckpt_path)\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98bf9c38-5b68-42a3-af8b-5234c0d5577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 780  622 2444]\n",
      "[0.00128205 0.00160772 0.00040917]\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "transform = get_random_transform()\n",
    "tr_dataset = TMED2(\n",
    "    split = \"train\", # train/val/test/all/unlabeled\n",
    "    transform = transform,\n",
    "    parasternal_only = True,\n",
    "    label_scheme_name = 'tufts',\n",
    ")\n",
    "tr_dataloader = torch.utils.data.DataLoader(tr_dataset, batch_size=batch_size, sampler = tr_dataset.class_sampler())\n",
    "\n",
    "va_transform = get_deterministic_transform()\n",
    "va_dataset = TMED2(\n",
    "    split = \"val\", # train/val/test/all/unlabeled\n",
    "    transform = va_transform,\n",
    "    parasternal_only = True,\n",
    "    label_scheme_name = 'tufts',\n",
    ")\n",
    "va_dataloader = torch.utils.data.DataLoader(va_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4fc95f-8462-4b29-b883-73bd1e9bff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.1183, -0.0241, -0.2758],\n",
      "        [ 0.1444, -0.0861, -0.1124],\n",
      "        [-0.0420,  0.0587,  0.0451],\n",
      "        [ 0.2020, -0.0809, -0.2038],\n",
      "        [-0.3101, -0.3292, -0.1161],\n",
      "        [ 0.5297, -0.0333, -0.1563],\n",
      "        [ 0.3890, -0.0400,  0.1799],\n",
      "        [ 0.1314, -0.0626,  0.1683],\n",
      "        [-0.2073,  0.2356,  0.0367],\n",
      "        [ 0.2517,  0.1855, -0.2147],\n",
      "        [ 0.2597,  0.0150, -0.4146],\n",
      "        [-0.1966, -0.0734, -0.0324],\n",
      "        [ 0.1652, -0.3199, -0.2715],\n",
      "        [ 0.0758,  0.1185,  0.0153],\n",
      "        [ 0.0391,  0.0069,  0.0543],\n",
      "        [-0.0601, -0.1089,  0.0041]], device='cuda:3',\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2966,  0.1669],\n",
      "        [-0.0119,  0.1034],\n",
      "        [-0.1613,  0.3144],\n",
      "        [ 0.2857,  0.0116],\n",
      "        [ 0.0330,  0.1729],\n",
      "        [-0.2105,  0.0838],\n",
      "        [ 0.0660,  0.3678],\n",
      "        [-0.2163,  0.0780],\n",
      "        [-0.3005,  0.0747],\n",
      "        [-0.3021,  0.2450],\n",
      "        [-0.0512, -0.1120],\n",
      "        [-0.1931,  0.2655],\n",
      "        [-0.1051,  0.0998],\n",
      "        [-0.2132,  0.0713],\n",
      "        [ 0.0422,  0.4806],\n",
      "        [-0.2362,  0.1754]], device='cuda:3', grad_fn=<AddmmBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# instantiate trainable parameters, loss and optimizer\n",
    "\n",
    "class Heads(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes_AS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if hidden_dim == 0:\n",
    "            self.as_head = nn.Linear(embedding_dim, num_classes_AS)\n",
    "            self.view_head = nn.Linear(embedding_dim, 2)\n",
    "        else:\n",
    "            self.as_head = nn.Sequential(nn.Linear(embedding_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, num_classes_AS))\n",
    "            self.view_head = nn.Sequential(nn.Linear(embedding_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 2))\n",
    "    def forward(self, z):\n",
    "        return self.as_head(z), self.view_head(z)\n",
    "        \n",
    "linear_probe = Heads(embedding_dim, hidden_dim, num_classes_AS).to(device)\n",
    "# test the linear probe\n",
    "print(linear_probe(torch.randn(batch_size, embedding_dim).to(device)))\n",
    "\n",
    "tuner = torch.optim.Adam(linear_probe.parameters(), lr=lr)\n",
    "loss_fcn = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ce53ca-8c28-438c-a76c-275b35253574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    with torch.no_grad():\n",
    "        features = model(x)\n",
    "    logits_as, logits_v = linear_probe(features)\n",
    "    return logits_as, logits_v\n",
    "    \n",
    "def train_batch(batch):\n",
    "    x, [y, y_v] = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_v = y_v.to(device)\n",
    "\n",
    "    tuner.zero_grad()\n",
    "    logits_as, logits_v = forward(x)\n",
    "    loss = loss_fcn(logits_as, y) + 0.1 * loss_fcn(logits_v, y_v)\n",
    "    loss.backward()\n",
    "    tuner.step()\n",
    "    return loss.item()\n",
    "\n",
    "def val_batch(batch):\n",
    "    x, [y, y_v] = batch\n",
    "    x = x.to(device)\n",
    "    y = y.cpu().numpy()\n",
    "    y_v = y_v.cpu().numpy()\n",
    "\n",
    "    logits_as, logits_v = forward(x)\n",
    "    pred_as = torch.argmax(logits_as, dim=1).cpu().numpy()\n",
    "    pred_v = torch.argmax(logits_v, dim=1).cpu().numpy()\n",
    "    return {'y_as':y, 'y_v':y_v, 'p_as':pred_as, 'p_v':pred_v}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf5b7902-9294-4d4b-b3fc-c0156e25aae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 241/241 [00:39<00:00,  6.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:17<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: tr_loss 0.990, as acc/f1 0.536/0.457, view acc/f1 0.914/0.885\n",
      "[[ 93  90 103]\n",
      " [ 22 100  65]\n",
      " [123 205 509]]\n",
      "[[925  40]\n",
      " [ 73 272]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:45<00:00,  5.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:17<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: tr_loss 0.890, as acc/f1 0.496/0.453, view acc/f1 0.921/0.898\n",
      "[[176  47  63]\n",
      " [ 77  76  34]\n",
      " [315 124 398]]\n",
      "[[909  56]\n",
      " [ 48 297]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:45<00:00,  5.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:11<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2: tr_loss 0.840, as acc/f1 0.498/0.456, view acc/f1 0.916/0.881\n",
      "[[168  72  46]\n",
      " [ 55  88  44]\n",
      " [232 209 396]]\n",
      "[[955  10]\n",
      " [100 245]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:44<00:00,  5.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:16<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3: tr_loss 0.810, as acc/f1 0.564/0.487, view acc/f1 0.913/0.876\n",
      "[[119  79  88]\n",
      " [ 24  90  73]\n",
      " [114 193 530]]\n",
      "[[957   8]\n",
      " [106 239]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:43<00:00,  5.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:11<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4: tr_loss 0.790, as acc/f1 0.582/0.504, view acc/f1 0.915/0.880\n",
      "[[168  36  82]\n",
      " [ 37  68  82]\n",
      " [189 122 526]]\n",
      "[[955  10]\n",
      " [101 244]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:45<00:00,  5.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:18<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5: tr_loss 0.736, as acc/f1 0.631/0.518, view acc/f1 0.924/0.900\n",
      "[[146  34 106]\n",
      " [ 24  55 108]\n",
      " [119  92 626]]\n",
      "[[930  35]\n",
      " [ 64 281]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:40<00:00,  5.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:12<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6: tr_loss 0.716, as acc/f1 0.656/0.520, view acc/f1 0.922/0.891\n",
      "[[129  31 126]\n",
      " [ 15  48 124]\n",
      " [ 88  66 683]]\n",
      "[[956   9]\n",
      " [ 93 252]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:44<00:00,  5.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:16<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7: tr_loss 0.713, as acc/f1 0.619/0.524, view acc/f1 0.937/0.914\n",
      "[[134  47 105]\n",
      " [ 14  75  98]\n",
      " [110 125 602]]\n",
      "[[952  13]\n",
      " [ 70 275]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:41<00:00,  5.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:12<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8: tr_loss 0.691, as acc/f1 0.643/0.515, view acc/f1 0.934/0.914\n",
      "[[161  18 107]\n",
      " [ 28  41 118]\n",
      " [141  56 640]]\n",
      "[[933  32]\n",
      " [ 54 291]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:43<00:00,  5.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:16<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9: tr_loss 0.692, as acc/f1 0.560/0.505, view acc/f1 0.906/0.863\n",
      "[[170  56  60]\n",
      " [ 31  89  67]\n",
      " [183 179 475]]\n",
      "[[960   5]\n",
      " [118 227]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:39<00:00,  6.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:14<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10: tr_loss 0.657, as acc/f1 0.616/0.522, view acc/f1 0.928/0.902\n",
      "[[165  30  91]\n",
      " [ 33  62  92]\n",
      " [157 100 580]]\n",
      "[[946  19]\n",
      " [ 75 270]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:43<00:00,  5.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:14<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11: tr_loss 0.657, as acc/f1 0.587/0.514, view acc/f1 0.930/0.903\n",
      "[[144  63  79]\n",
      " [ 20  86  81]\n",
      " [116 182 539]]\n",
      "[[955  10]\n",
      " [ 82 263]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:40<00:00,  5.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:13<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12: tr_loss 0.638, as acc/f1 0.561/0.508, view acc/f1 0.927/0.899\n",
      "[[206  36  44]\n",
      " [ 47  78  62]\n",
      " [227 159 451]]\n",
      "[[956   9]\n",
      " [ 86 259]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:39<00:00,  6.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:12<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13: tr_loss 0.608, as acc/f1 0.635/0.531, view acc/f1 0.931/0.904\n",
      "[[140  41 105]\n",
      " [ 18  67 102]\n",
      " [ 93 119 625]]\n",
      "[[954  11]\n",
      " [ 80 265]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:42<00:00,  5.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:14<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14: tr_loss 0.602, as acc/f1 0.627/0.532, view acc/f1 0.929/0.902\n",
      "[[146  39 101]\n",
      " [ 20  71  96]\n",
      " [113 119 605]]\n",
      "[[951  14]\n",
      " [ 79 266]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:41<00:00,  5.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:11<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15: tr_loss 0.585, as acc/f1 0.598/0.478, view acc/f1 0.927/0.898\n",
      "[[ 90  73 123]\n",
      " [  9  71 107]\n",
      " [ 55 160 622]]\n",
      "[[954  11]\n",
      " [ 85 260]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:45<00:00,  5.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:17<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  16: tr_loss 0.583, as acc/f1 0.556/0.503, view acc/f1 0.939/0.918\n",
      "[[178  52  56]\n",
      " [ 37  87  63]\n",
      " [205 168 464]]\n",
      "[[947  18]\n",
      " [ 62 283]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:40<00:00,  5.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:11<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  17: tr_loss 0.575, as acc/f1 0.639/0.538, view acc/f1 0.931/0.910\n",
      "[[140  49  97]\n",
      " [ 14  70 103]\n",
      " [ 80 130 627]]\n",
      "[[930  35]\n",
      " [ 55 290]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:47<00:00,  5.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:19<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  18: tr_loss 0.565, as acc/f1 0.626/0.531, view acc/f1 0.933/0.910\n",
      "[[155  49  82]\n",
      " [ 18  67 102]\n",
      " [107 132 598]]\n",
      "[[940  25]\n",
      " [ 63 282]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:38<00:00,  6.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:11<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19: tr_loss 0.547, as acc/f1 0.634/0.528, view acc/f1 0.934/0.910\n",
      "[[154  44  88]\n",
      " [ 19  59 109]\n",
      " [114 105 618]]\n",
      "[[948  17]\n",
      " [ 70 275]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 241/241 [00:47<00:00,  5.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 82/82 [00:18<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20: tr_loss 0.540, as acc/f1 0.597/0.516, view acc/f1 0.934/0.909\n",
      "[[157  52  77]\n",
      " [ 23  72  92]\n",
      " [123 161 553]]\n",
      "[[951  14]\n",
      " [ 73 272]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/241 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m linear_probe\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m tr_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(tr_dataloader):\n\u001b[1;32m      6\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m train_batch(batch)\n\u001b[1;32m      7\u001b[0m     tr_loss\u001b[38;5;241m.\u001b[39mappend(batch_loss)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/workspace/dino_lowrank/src/dataloader_tmed.py:193\u001b[0m, in \u001b[0;36mTMED2.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    190\u001b[0m         y_view \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(tmed_view_schemes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m][view])\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    # train the model\n",
    "    linear_probe.train()\n",
    "    tr_loss = []\n",
    "    for batch in tqdm(tr_dataloader):\n",
    "        batch_loss = train_batch(batch)\n",
    "        tr_loss.append(batch_loss)\n",
    "    # validate the model\n",
    "    linear_probe.eval()\n",
    "    cache = {}\n",
    "    for c in ['y_as', 'y_v', 'p_as', 'p_v']:\n",
    "        cache[c] = []\n",
    "    for batch in tqdm(va_dataloader):\n",
    "        batch_outs = val_batch(batch)\n",
    "        for k in batch_outs.keys():\n",
    "            cache[k].extend(batch_outs[k])\n",
    "    # evaluate acc and f1\n",
    "    for k in cache.keys():\n",
    "        cache[k] = np.array(cache[k]).squeeze()\n",
    "    acc_as = sum(cache['y_as'] == cache['p_as'])/len(cache['y_as'])\n",
    "    acc_v = sum(cache['y_v'] == cache['p_v'])/len(cache['y_v'])\n",
    "    f1_as = f1_score(cache['y_as'], cache['p_as'], average='macro')\n",
    "    f1_v = f1_score(cache['y_v'], cache['p_v'], average='macro')\n",
    "    print(\"Epoch %3d: tr_loss %.3f, as acc/f1 %.3f/%.3f, view acc/f1 %.3f/%.3f\" % (i, np.mean(tr_loss), acc_as, f1_as, acc_v, f1_v))\n",
    "    print(confusion_matrix(cache['y_as'], cache['p_as']))\n",
    "    print(confusion_matrix(cache['y_v'], cache['p_v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450562d-6c30-4d4c-bbfa-03bc944e28af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
