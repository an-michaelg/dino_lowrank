{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed883c2-c9f9-4b49-a2d5-e555f5f31acb",
   "metadata": {},
   "source": [
    "## Explore which features can be extracted from the DINO backbone and their dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2afa6b-cabf-472b-9e46-6a3e33025238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.hub.set_dir(\"../pretrained_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf77dcc-56e6-4fa3-8fa2-90e4a62cbc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to ../pretrained_weights/main.zip\n",
      "/workspace/dino_lowrank/src/../pretrained_weights/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/workspace/dino_lowrank/src/../pretrained_weights/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/workspace/dino_lowrank/src/../pretrained_weights/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to ../pretrained_weights/checkpoints/dinov2_vits14_pretrain.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 84.2M/84.2M [00:00<00:00, 104MB/s]\n"
     ]
    }
   ],
   "source": [
    "# load the backbone model\n",
    "device = 'cpu' #0 if torch.cuda.is_available() else \"cpu\"\n",
    "dino_backbone = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1680c8d-1932-4f40-884e-bcf2757a5160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DinoVisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x NestedTensorBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MemEffAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): LayerScale()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): LayerScale()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(dino_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff2ab13-4803-4303-8652-f9944d55593a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 384])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, the default backbone.forward method returns class token\n",
    "in_tensor = torch.randn(8, 3, 224, 224).to(device) # BxCxHxW\n",
    "out = dino_backbone(in_tensor)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6696bf26-f9e5-491f-9dd0-19bc8a9ab7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_norm_clstoken: shape:torch.Size([8, 384])\n",
      "x_norm_regtokens: shape:torch.Size([8, 0, 384])\n",
      "x_norm_patchtokens: shape:torch.Size([8, 256, 384])\n",
      "x_prenorm: shape:torch.Size([8, 257, 384])\n",
      "masks: shape:None\n"
     ]
    }
   ],
   "source": [
    "# The backbone.forward_features method returns multiple outputs from the final DINO block\n",
    "out_features = dino_backbone.forward_features(in_tensor)\n",
    "for k in out_features.keys():\n",
    "    shape = None if out_features[k] is None else out_features[k].shape\n",
    "    print(f\"{k}: shape:{shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ac264d-f0d7-48d8-b225-4f1a8d54ae10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The class token is equivalent to the default forward method output\n",
    "out == out_features['x_norm_clstoken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37500121-6bde-458c-b35e-b67dad27ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The official DINOv2 repo has a function called forward_features_list, but it is not used in their experiments\n",
    "# Instead, they use get_intermediate_layers, so let's try that\n",
    "# The default configuration for this function is n=1, reshape=False, return_class_token=False, norm=True\n",
    "n_last_blocks = 3\n",
    "out_layers = dino_backbone.get_intermediate_layers(in_tensor, n=n_last_blocks, reshape=False, return_class_token=True, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f112d32-c3b9-42e2-9b4c-f221b5a0d40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 384])\n",
      "torch.Size([8, 384])\n"
     ]
    }
   ],
   "source": [
    "# The interpretation of the out_layers is as follows:\n",
    "# out_layers[i][0] is the patch tokens for the i-th layer, but counted forwards from the n_last_blocks\n",
    "# Eg. if n_last_blocks=4, then i=0 would be taking from the 4th-last block, i=3 would be taking from the last block\n",
    "# out_layers[i][1] is the class token for the i-th layer\n",
    "# If reshape=True, that means the patch tokens are reshaped to 16x16\n",
    "print(out_layers[0][0].shape)\n",
    "print(out_layers[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50cfd4a-452e-4a32-a0eb-eb4c7c6c93f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class token equivalence\n",
    "out_layers[2][1] == out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b1f99d-8eaf-4b73-99b3-feae1c554092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patch tokens equivalence\n",
    "out_layers[2][0] == out_features['x_norm_patchtokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60330d63-c468-4a16-a83a-3f41e3f12a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
